<configuration>
    <property>
    <name>fs.file.impl.disable.cache</name>
    <value>true</value>
  </property> 
    <property>
      <name>fs.hdfs.impl.disable.cache</name>
      <value>true</value>
    </property> 
    
        <!--
                This focuses on joins, conversion to map joins and the size up to 
                        which tables will be converted to ma joins
        -->
    <property>
    <name>hive.auto.convert.join</name>
    <value>true</value>
  </property> 


    <property>
    <name>hive.auto.convert.join.noconditionaltask</name>
    <value>true</value>
  </property> 


    <property>
    <name>hive.auto.convert.join.noconditionaltask.size</name>
    <value>1200000000</value>
  </property> 


    <property>
    <name>hive.auto.convert.sortmerge.join</name>
    <value>true</value>
  </property> 


    <property>
    <name>hive.auto.convert.sortmerge.join.noconditionaltask</name>
    <value>true</value>
  </property> 


        <!--
                These are focused around the Transactions in Hive and 
                        the internal compaction parameters round them
        -->
    <property>
    <name>hive.compactor.abortedtxn.threshold</name>
    <value>1000</value>
  </property> 


    <property>
    <name>hive.compactor.check.interval</name>
    <value>300L</value>
  </property> 


    <property>
      <name>hive.heapsize</name>
      <value>1024</value>
    </property> 


    <property>
    <name>hive.compactor.delta.num.threshold</name>
    <value>10</value>
  </property> 


    <property>
    <name>hive.compactor.delta.pct.threshold</name>
    <value>0.1f</value>
  </property> 


    <property>
    <name>hive.compactor.initiator.on</name>
    <value>false</value>
  </property> 


    <property>
    <name>hive.compactor.worker.threads</name>
    <value>0</value>
  </property> 


    <property>
    <name>hive.compactor.worker.timeout</name>
    <value>86400L</value>
  </property> 


    <property>
    <name>hive.txn.manager</name>
    <value>org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager</value>
  </property> 


    <property>
    <name>hive.txn.max.open.batch</name>
    <value>1000</value>
  </property> 


    <property>
    <name>hive.txn.timeout</name>
    <value>300</value>
  </property> 


        <!--
                These are focused query compilation and optimizations
        -->


    <property>
    <name>hive.compute.query.using.stats</name>
    <value>true</value>
  </property> 


    <property>
    <name>hive.stats.autogather</name>
    <value>true</value>
  </property> 


    <property>
    <name>hive.stats.dbclass</name>
    <value>fs</value>
  </property> 


    <property>
    <name>hive.enforce.bucketing</name>
    <value>true</value>
  </property> 


    <property>
    <name>hive.enforce.sorting</name>
    <value>true</value>
  </property> 


    <property>
    <name>hive.enforce.sortmergebucketmapjoin</name>
    <value>true</value>
  </property> 






    <property>
    <name>hive.limit.pushdown.memory.usage</name>
    <value>0.04</value>
  </property> 


    <property>
    <name>hive.map.aggr</name>
    <value>true</value>
  </property> 


    <property>
    <name>hive.mapjoin.bucket.cache.size</name>
    <value>10000</value>
  </property> 


    <property>
    <name>hive.mapred.reduce.tasks.speculative.execution</name>
    <value>false</value>
  </property> 
    <property>
    <name>hive.optimize.bucketmapjoin</name>
    <value>true</value>
  </property> 


    <property>
    <name>hive.optimize.bucketmapjoin.sortedmerge</name>
    <value>false</value>
  </property> 


    <property>
    <name>hive.optimize.index.filter</name>
    <value>true</value>
  </property> 


    <property>
    <name>hive.optimize.mapjoin.mapreduce</name>
    <value>true</value>
  </property> 


    <property>
    <name>hive.optimize.reducededuplication</name>
    <value>true</value>
  </property> 


    <property>
    <name>hive.optimize.reducededuplication.min.reducer</name>
    <value>4</value>
  </property> 


        <!--
                These are focused around providing hookd for the ATS server where 
                        most of the Hive logs are kept
            -->


    <property>
    <name>hive.exec.failure.hooks</name>
    <value>org.apache.hadoop.hive.ql.hooks.ATSHook</value>
  </property> 


    <property>
    <name>hive.exec.post.hooks</name>
    <value>org.apache.hadoop.hive.ql.hooks.ATSHook</value>
  </property> 


    <property>
    <name>hive.exec.pre.hooks</name>
    <value>org.apache.hadoop.hive.ql.hooks.ATSHook</value>
  </property> 


        <!--
                These are focused around Hive metastore interaction
            -->


    <property>
    <name>hive.metastore.cache.pinobjtypes</name>
    <value>Table,Database,Type,FieldSchema,Order</value>
  </property> 


    <property>
    <name>hive.metastore.client.socket.timeout</name>
    <value>60</value>
  </property> 


    <property>
    <name>hive.metastore.execute.setugi</name>
    <value>true</value>
  </property> 
    
    <property>
    <name>hive.metastore.warehouse.dir</name>
    <value>/apps/hive/warehouse</value>
  </property> 




    <property>
    <name>hive.orc.splits.include.file.footer</name>
    <value>false</value>
  </property> 


        <!--
                These are focused around deciding the execution engine, the workload management queues etc.
            -->


    <property>
    <name>hive.execution.engine</name>
    <value>mr</value>
  </property> 


    <property>
    <name>hive.server2.enable.doAs</name>
    <value>false</value>
  </property> 


    <property>
    <name>hive.server2.tez.default.queues</name>
    <value>default</value>
  </property> 


    <property>
    <name>hive.server2.tez.initialize.default.sessions</name>
    <value>false</value>
  </property> 


    <property>
    <name>hive.server2.tez.sessions.per.default.queue</name>
    <value>1</value>
  </property> 








    <property>
    <name>hive.tez.container.size</name>
    <value>-1</value>
    <description>If this is not specified (-1), the memory settings from the MapReduce configurations (mapreduce.map.memory.mb) will be used by default.</description>
  </property> 


    <property>
    <name>hive.tez.input.format</name>
    <value>org.apache.hadoop.hive.ql.io.HiveInputFormat</value>
  </property> 


    <property>
    <name>hive.tez.java.opts</name>
    <value/>
    <description>If this is not specified, the MapReduce java opts settings (mapreduce.map.java.opts) will be used by default.</description>
  </property> 




    <property>
    <name>hive.vectorized.execution.enabled</name>
    <value>true</value>
  </property> 


    <property>
    <name>hive.vectorized.groupby.checkinterval</name>
    <value>4096</value>
  </property> 


        <!--
                These properties need to be modified to setup the connection to Hive correctly
            -->


    <property>
  <name>javax.jdo.option.ConnectionDriverName</name>
  <value>TODO-HIVE-METASTORE-DB-CONNECTION-DRIVER-NAME</value>
  <description>Enter your Hive Metastore Connection Driver Name, for example if MySQL: com.mysql.jdbc.Driver</description>
</property> 


    <property>       
   <name>javax.jdo.option.ConnectionPassword</name>       
   <value>TODO-HIVE-METASTORE-DB-PASSWORD</value>  
   <description>Enter your Hive Metastore database password.</description>
  </property> 


    <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://TODO-HIVE-METASTORE-DB-SERVER:TODO-HIVE-METASTORE-DB-PORT/TODO-HIVE-METASTORE-DB-NAME?createDatabaseIfNotExist=true</value>
    <description>Enter your Hive Metastore Connection URL, for example if MySQL: jdbc:mysql://localhost:3306/mysql?createDatabaseIfNotExist=true</description>    
  </property> 


    <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>TODO-HIVE-METASTORE-DB-USER-NAME</value>
    <description>Enter your Hive Metastore database user name.</description>
  </property> 
  


        <!--
                Secure settings for Kerberized cluster
           -->


    <property>
    <name>hive.security.authenticator.manager</name>
    <value>org.apache.hadoop.hive.ql.security.ProxyUserAuthenticator</value>
  </property> 
  
    <property>
    <name>hive.security.authorization.enabled</name>
    <value>false</value>
  </property> 
  
    <property>
    <name>hive.security.authorization.manager</name>
    <value>org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider</value>
  </property> 
  
    <property>
    <name>hive.security.metastore.authorization.manager</name>
    <value>org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider</value>
  </property> 
  
  
    <property>
      <name>hive.server2.authentication</name>
      <value>KERBEROS</value>
    </property> 
    
    <property>
      <name>hive.server2.authentication.kerberos.keytab</name>
      <value>/etc/security/keytabs/hive.service.keytab</value>
    </property> 
    
    <property>
      <name>hive.server2.authentication.kerberos.principal</name>
      <value>hive/_HOST@HDPSECB.SUPSECB.COM</value>
    </property>
  


        <!--
                Hive Metastore secure settings
           -->


        <property>
      <name>hive.metastore.kerberos.keytab.file</name>
      <value>/etc/security/keytabs/hive.service.keytab</value>
    </property> 


    <property>
      <name>hive.metastore.kerberos.principal</name>
      <value>hive/_HOST@HDPSECB.SUPSECB.COM</value>
    </property> 


    <property>
      <name>hive.metastore.sasl.enabled</name>
      <value>true</value>
    </property> 
    
    <property>    
        <name>hive.metastore.cache.pinobjtypes</name>    
        <value>Table,Database,Type,FieldSchema,Order</value>    
        <description>List of comma separated metastore object types that should be pinned in
        the cache</description>  
</property>


  


        <!--
                Hive Metastore HA settings and HA settings for secure cluster
           -->
  
 <property>
 <name> hive.metastore.uris </name>
 <value> thrift://$Hive_Metastore_Server_Host_Machine_FQDN </value>
 <description> A comma separated list of metastore uris on which metastore service is running </description>
 </property> -->




<property>
 <name> hive.cluster.delegation.token.store.class </name>
 <value> org.apache.hadoop.hive.thrift.DBTokenStore </value>
 </property>




</configuration>