
# Hadoop HDFS NameNode Check

Check the health of the NameNode(s).

In HA mode, we need to ensure both NameNodes are installed before testing SSH
Fencing. Otherwise, a race condition may occur if a host attempt to connect
through SSH over another one where the public key isn't yet deployed.

    module.exports = header: 'HDFS NN Check', timeout: -1, label_true: 'CHECKED', label_false: 'SKIPPED', handler: ->
      {user, hdfs, active_nn_host, nameservice, force_check, check_hdfs_fsck} = @config.ryba

## Wait

Wait for the HDFS NameNode to be started.

      @call once: true, 'ryba/hadoop/hdfs_nn/wait'

## Check HTTP

      is_ha = @hosts_with_module('ryba/hadoop/hdfs_nn').length > 1
      # state = if not is_ha or active_nn_host is @config.host then 'active' else 'standby'
      protocol = if hdfs.nn.site['dfs.http.policy'] is 'HTTP_ONLY' then 'http' else 'https'
      nameservice = if is_ha then ".#{@config.ryba.hdfs.nn.site['dfs.nameservices']}" else ''
      shortname = if is_ha then ".#{@config.shortname}" else ''
      address = hdfs.nn.site["dfs.namenode.#{protocol}-address#{nameservice}#{shortname}"]
      [_, port] = address.split ':'
      securityEnabled = protocol is 'https'
      @execute
        header: 'HTTP'
        cmd: mkcmd.hdfs @, "curl --negotiate -k -u : #{protocol}://#{@config.host}:#{port}/jmx?qry=Hadoop:service=NameNode,name=NameNodeStatus"
      , (err, executed, stdout) ->
        throw err if err
        data = JSON.parse stdout
        # After HDP2.2, the response needs some time before returning any beans
        throw Error "Invalid Response" unless Array.isArray data?.beans
        # throw Error "Invalid Response" unless /^Hadoop:service=NameNode,name=NameNodeStatus$/.test data?.beans[0]?.name
        # throw Error "WARNING: Invalid security (#{data.beans[0].SecurityEnabled}, instead of #{securityEnabled}" unless data.beans[0].SecurityEnabled is securityEnabled

## Check Health

Connect to the provided NameNode to check its health. The NameNode is capable of
performing some diagnostics on itself, including checking if internal services
are running as expected. This command will return 0 if the NameNode is healthy,
non-zero otherwise. One might use this command for monitoring purposes.

Checkhealth return result is not completely implemented
See More http://hadoop.apache.org/docs/r2.0.2-alpha/hadoop-yarn/hadoop-yarn-site/HDFSHighAvailability.html#Administrative_commands

      @execute
        header: 'HDFS NN # Check HA Health'
        if: -> @hosts_with_module('ryba/hadoop/hdfs_nn').length > 1
        cmd: mkcmd.hdfs @, "hdfs --config '#{hdfs.nn.conf_dir}' haadmin -checkHealth #{@config.shortname}"

## Check FSCK

Check for various inconsistencies on the overall filesystem. Use the command
`hdfs fsck -list-corruptfileblocks` to list the corrupted blocks.

Corrupted blocks for removal can be found with the command: 
`hdfs fsck / | egrep -v '^\.+$' | grep -v replica | grep -v Replica`
Additionnal information may be found on the [CentOS HowTos site][corblk].

[corblk]: http://centoshowtos.org/hadoop/fix-corrupt-blocks-on-hdfs/

      check_hdfs_fsck = if check_hdfs_fsck? then !!check_hdfs_fsck else true
      @execute
        header: 'FSCK'
        retry: 3
        wait: 60000
        timeout: -1
        cmd: mkcmd.hdfs @, "exec 5>&1; hdfs fsck / | tee /dev/fd/5 | tail -1 | grep HEALTHY 1>/dev/null"
        if: force_check or check_hdfs_fsck

## Check HDFS

Attemp to place a file inside HDFS. the file "/etc/passwd" will be placed at
"/user/{test\_user}/#{@config.host}\_dn".

      @execute
        header: 'HDFS'
        cmd: mkcmd.test @, """
        if hdfs --config '#{hdfs.nn.conf_dir}' dfs -test -f /user/#{user.name}/#{@config.host}-nn; then exit 2; fi
        echo 'Upload file to HDFS'
        hdfs --config '#{hdfs.nn.conf_dir}' dfs -put /etc/passwd /user/#{user.name}/#{@config.host}-nn
        """
        code_skipped: 2

## Check WebHDFS

Check the Kerberos SPNEGO and the Hadoop delegation token. Will only be
executed if the file "/user/{test\_user}/{host}\_webhdfs" generated by this action
is not present on HDFS.

Read [Delegation Tokens in Hadoop Security](http://www.kodkast.com/blogs/hadoop/delegation-tokens-in-hadoop-security)
for more information.

      @call header: 'HDFS DN # Check WebHDFS', timeout: -1, label_true: 'CHECKED', label_false: 'SKIPPED', handler: ->
        is_ha = @hosts_with_module('ryba/hadoop/hdfs_nn').length > 1
        protocol = if hdfs.nn.site['dfs.http.policy'] is 'HTTP_ONLY' then 'http' else 'https'
        nameservice = if is_ha then ".#{@config.ryba.hdfs.nn.site['dfs.nameservices']}" else ''
        shortname = if is_ha then ".#{@contexts(hosts: active_nn_host)[0].config.shortname}" else ''
        address = hdfs.nn.site["dfs.namenode.#{protocol}-address#{nameservice}#{shortname}"]
        @execute
          cmd: mkcmd.test @, """
          hdfs --config '#{hdfs.nn.conf_dir}' dfs -touchz check-#{@config.shortname}-webhdfs
          kdestroy
          """
          code_skipped: 2
        @execute
          cmd: mkcmd.test @, """
          curl -s --negotiate --insecure -u : "#{protocol}://#{address}/webhdfs/v1/user/#{user.name}?op=LISTSTATUS"
          kdestroy
          """
        , (err, executed, stdout) ->
          throw err if err
          try
            count = JSON.parse(stdout).FileStatuses.FileStatus.filter((e) => e.pathSuffix is "check-#{@config.shortname}-webhdfs").length
          catch e then throw Error e
          throw Error "Invalid result" unless count
        @execute
          cmd: mkcmd.test @, """
          curl -s --negotiate --insecure -u : "#{protocol}://#{address}/webhdfs/v1/?op=GETDELEGATIONTOKEN"
          kdestroy
          """
        , (err, executed, stdout) ->
          throw err if err
          json = JSON.parse(stdout)
          return setTimeout do_tocken, 3000 if json.exception is 'RetriableException'
          token = json.Token.urlString
          @execute
            cmd: """
            curl -s --insecure "#{protocol}://#{address}/webhdfs/v1/user/#{user.name}?delegation=#{token}&op=LISTSTATUS"
            """
          , (err, executed, stdout) ->
            throw err if err
            try
              count = JSON.parse(stdout).FileStatuses.FileStatus.filter((e) => e.pathSuffix is "check-#{@config.shortname}-webhdfs").length
            catch e then throw Error e
            throw Error "Invalid result" unless count

## Dependencies

    mkcmd = require '../../lib/mkcmd'
