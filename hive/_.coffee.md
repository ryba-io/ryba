---
title: 
layout: module
---

# Hive

    module.exports = []
    module.exports.push 'masson/bootstrap/'
    module.exports.push 'masson/commons/java'
    module.exports.push 'ryba/hadoop/core'
    module.exports.push 'ryba/hadoop/hdfs_client'
    module.exports.push 'ryba/hadoop/core' # Hive dependency, need to create user and group for zookeeper

## Configure

*   `hive_user` (object|string)   
    The Unix Hive login name or a user object (see Mecano User documentation).   
*   `hive_group` (object|string)   
    The Unix Hive group name or a group object (see Mecano Group documentation).   

Example:

```json
{
  "hdp": {
    "hive_user": {
      "name": "hive", "system": true, "gid": "hive",
      "comment": "Hive User", "home": "/home/hive"
    }
    "hive_group": {
      "name": "hive", "system": true
    }
  }
}
```

    module.exports.push module.exports.configure = (ctx) ->
      return if ctx.hive__configured
      ctx.hive__configured = true
      require('masson/commons/java').configure ctx
      require('../hadoop/core').configure ctx
      {static_host, realm} = ctx.config.hdp
      ctx.config.hdp.hive_conf_dir ?= '/etc/hive/conf'
      metastore_host = ctx.config.hdp.hive_metastore_host ?= ctx.host_with_module 'ryba/hive/server'
      ctx.config.hdp.hive_metastore_port ?= 9083
      ctx.config.hdp.hive_metastore_timeout ?= 20000 # 20s
      ctx.config.hdp.hive_server2_host ?= ctx.host_with_module 'ryba/hive/server'
      ctx.config.hdp.hive_server2_port ?= 10001
      ctx.config.hdp.hive_server2_timeout ?= 20000 # 20s
      # User
      ctx.config.hdp.hive_user = name: ctx.config.hdp.hive_user if typeof ctx.config.hdp.hive_user is 'string'
      ctx.config.hdp.hive_user ?= {}
      ctx.config.hdp.hive_user.name ?= 'hive'
      ctx.config.hdp.hive_user.system ?= true
      ctx.config.hdp.hive_user.gid ?= 'hive'
      ctx.config.hdp.hive_user.comment ?= 'Hive User'
      ctx.config.hdp.hive_user.home ?= '/var/lib/hive'
      # Group
      ctx.config.hdp.hive_group = name: ctx.config.hdp.hive_group if typeof ctx.config.hdp.hive_group is 'string'
      ctx.config.hdp.hive_group ?= {}
      ctx.config.hdp.hive_group.name ?= 'hive'
      ctx.config.hdp.hive_group.system ?= true
      # Configuration
      ctx.config.hdp.hive_site ?= {}
      ctx.config.hdp.hive_site['hive.metastore.local'] = null
      ctx.config.hdp.hive_site['hive.metastore.uris'] ?= "thrift://#{metastore_host}:9083"
      # To prevent memory leak in unsecure mode, disable [file system caches](https://cwiki.apache.org/confluence/display/Hive/Setting+up+HiveServer2)
      # , by setting following params to true
      ctx.config.hdp.hive_site['fs.hdfs.impl.disable.cache'] ?= 'false'
      ctx.config.hdp.hive_site['fs.file.impl.disable.cache'] ?= 'false'
      # TODO: encryption is only with Kerberos, need to check first
      # http://hortonworks.com/blog/encrypting-communication-between-hadoop-and-your-analytics-tools/?utm_source=feedburner&utm_medium=feed&utm_campaign=Feed%3A+hortonworks%2Ffeed+%28Hortonworks+on+Hadoop%29
      ctx.config.hdp.hive_site['hive.server2.thrift.sasl.qop'] ?= 'auth'
      # http://docs.hortonworks.com/HDPDocuments/HDP2/HDP-2.0.6.0/bk_installing_manually_book/content/rpm-chap14-2-3.html#rmp-chap14-2-3-5
      # If true, the metastore thrift interface will be secured with
      # SASL. Clients must authenticate with Kerberos.
      ctx.config.hdp.hive_site['hive.metastore.sasl.enabled'] ?= 'true'
      # The path to the Kerberos Keytab file containing the metastore
      # thrift server's service principal.
      ctx.config.hdp.hive_site['hive.metastore.kerberos.keytab.file'] ?= '/etc/hive/conf/hive.service.keytab'
      # The service principal for the metastore thrift server. The
      # special string _HOST will be replaced automatically with the correct  hostname.
      ctx.config.hdp.hive_site['hive.metastore.kerberos.principal'] ?= "hive/#{static_host}@#{realm}"
      ctx.config.hdp.hive_site['hive.metastore.cache.pinobjtypes'] ?= 'Table,Database,Type,FieldSchema,Order'
      # https://cwiki.apache.org/confluence/display/Hive/Setting+up+HiveServer2
      # Authentication type
      ctx.config.hdp.hive_site['hive.server2.authentication'] ?= 'KERBEROS'
      # The keytab for the HiveServer2 service principal
      # 'hive.server2.authentication.kerberos.keytab': "/etc/security/keytabs/hcat.service.keytab"
      ctx.config.hdp.hive_site['hive.server2.authentication.kerberos.keytab'] ?= '/etc/hive/conf/hive.service.keytab'
      # The service principal for the HiveServer2. If _HOST
      # is used as the hostname portion, it will be replaced.
      # with the actual hostname of the running instance.
      # 'hive.server2.authentication.kerberos.principal': "hcat/#{ctx.config.host}@#{realm}"
      ctx.config.hdp.hive_site['hive.server2.authentication.kerberos.principal'] ?= "hive/#{static_host}@#{realm}"
      ctx.config.hdp.hive_site['hive.security.authorization.manager'] ?= 'org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider'
      ctx.config.hdp.hive_site['hive.security.metastore.authorization.manager'] ?= 'org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider'
      ctx.config.hdp.hive_site['hive.security.authenticator.manager'] ?= 'org.apache.hadoop.hive.ql.security.ProxyUserAuthenticator'
      # see https://cwiki.apache.org/confluence/display/Hive/WebHCat+InstallWebHCat
      ctx.config.hdp.hive_site['hive.security.metastore.authenticator.manager'] ?= 'org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator'
      ctx.config.hdp.hive_site['hive.metastore.pre.event.listeners'] ?= 'org.apache.hadoop.hive.ql.security.authorization.AuthorizationPreEventListener'

## Users & Groups

By default, the "hive" and "hive-hcatalog" packages create the following
entries:

```bash
cat /etc/passwd | grep hive
hive:x:493:493:Hive:/var/lib/hive:/sbin/nologin
cat /etc/group | grep hive
hive:x:493:
```

    module.exports.push name: 'HDP Hive & HCat # Users & Groups', callback: (ctx, next) ->
      {hive_group, hive_user} = ctx.config.hdp
      ctx.group hive_group, (err, gmodified) ->
        return next err if err
        ctx.user hive_user, (err, umodified) ->
          next err, if gmodified or umodified then ctx.OK else ctx.PASS

## Install

Instructions to [install the Hive and HCatalog RPMs](http://docs.hortonworks.com/HDPDocuments/HDP1/HDP-1.2.3/bk_installing_manually_book/content/rpm-chap6-1.html)

    module.exports.push name: 'HDP Hive & HCat # Install', timeout: -1, callback: (ctx, next) ->
      modified = false
      {java_home} = ctx.config.java
      {hive_conf_dir} = ctx.config.hdp
      do_hive = ->
        ctx.log 'Install the hive package'
        ctx.service name: 'hive', (err, serviced) ->
          return next err if err
          modified = true if serviced
          ctx.log 'Copy hive-env.sh'
          ctx.write
            source: "#{__dirname}/../hadoop/files/hive/hive-env.sh"
            destination: "#{hive_conf_dir}/hive-env.sh"
            local_source: true
            write: [
              match: /^export JAVA_HOME=.*$/mg
              replace: "export JAVA_HOME=#{java_home}"
            ]
          , (err, copied) ->
            return next err if err
            do_hcatalog()
      do_hcatalog = ->
        ctx.log 'Install the hcatalog package'
        ctx.service name: 'hive-hcatalog', (err, serviced) ->
          return next err if err
          modified = true if serviced
          do_end()
      do_end = ->
        next null, if modified then ctx.OK else ctx.PASS
      do_hive()




